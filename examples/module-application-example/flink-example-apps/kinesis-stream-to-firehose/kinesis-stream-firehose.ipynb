{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-firehose\n"
     ]
    }
   ],
   "source": [
    "from pyflink.table import EnvironmentSettings, TableEnvironment\n",
    "import os\n",
    "import json\n",
    "from pyflink.table.expressions import *\n",
    "from pyflink.table.window import *\n",
    "\n",
    "# Line only for Local Development\n",
    "os.environ[\"IS_LOCAL\"] = \"True\"\n",
    "\n",
    "print(os.path.abspath(os.getcwd()))\n",
    "#https://docs.aws.amazon.com/pt_br/managed-flink/latest/java/gs-python-createapp.html\n",
    "#https://github.com/aws-samples/amazon-kinesis-data-analytics-examples/blob/master/python/FirehoseSink/streaming-firehose-sink.py\n",
    "#https://github.com/aws-samples/amazon-kinesis-data-analytics-examples/blob/master/python/S3Sink/streaming-file-sink.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Flink locally...\n"
     ]
    }
   ],
   "source": [
    "# 1. Creates a Table Environment\n",
    "env_settings = EnvironmentSettings.in_streaming_mode()\n",
    "table_env = TableEnvironment.create(env_settings)\n",
    "\n",
    "statement_set = table_env.create_statement_set()\n",
    "\n",
    "APPLICATION_PROPERTIES_FILE_PATH = \"/etc/flink/application_properties.json\"  # on Kinesis Data Analytics\n",
    "\n",
    "is_local = (\n",
    "    True if os.environ.get(\"IS_LOCAL\") else False\n",
    ")  # set this env var in your local environment\n",
    "\n",
    "if is_local:\n",
    "    # only for local, overwrite variable to properties and pass in your jars delimited by a semicolon (;)\n",
    "    print(\"Running Flink locally...\")\n",
    "    APPLICATION_PROPERTIES_FILE_PATH = \"application_properties.json\"  # local\n",
    "\n",
    "    CURRENT_DIR = os.path.abspath(os.getcwd())\n",
    "    table_env.get_config().set(\n",
    "        \"pipeline.jars\",\n",
    "        f\"file:///{CURRENT_DIR}/lib/flink-sql-connector-aws-kinesis-firehose-4.1.0-1.17.jar;file:///{CURRENT_DIR}/lib/flink-sql-connector-kinesis-4.1.0-1.17.jar\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_application_properties():\n",
    "    if os.path.isfile(APPLICATION_PROPERTIES_FILE_PATH):\n",
    "        with open(APPLICATION_PROPERTIES_FILE_PATH, \"r\") as file:\n",
    "            contents = file.read()\n",
    "            properties = json.loads(contents)\n",
    "            return properties\n",
    "    else:\n",
    "        print('A file at \"{}\" was not found'.format(APPLICATION_PROPERTIES_FILE_PATH))\n",
    "\n",
    "\n",
    "def property_map(props, property_group_id):\n",
    "    for prop in props:\n",
    "        if prop[\"PropertyGroupId\"] == property_group_id:\n",
    "            return prop[\"PropertyMap\"]\n",
    "\n",
    "def create_source_table(table_name, stream_name, region, stream_initpos):\n",
    "    return \"\"\" CREATE TABLE IF NOT EXISTS {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3),\n",
    "                WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n",
    "\n",
    "              )\n",
    "              PARTITIONED BY (ticker)\n",
    "              WITH (\n",
    "                'connector' = 'kinesis',\n",
    "                'stream' = '{1}',\n",
    "                'aws.region' = '{2}',\n",
    "                'scan.stream.initpos' = '{3}',\n",
    "                'format' = 'json',\n",
    "                'json.timestamp-format.standard' = 'ISO-8601'\n",
    "              ) \"\"\".format(\n",
    "        table_name, stream_name, region, stream_initpos\n",
    "    )\n",
    "\n",
    "\n",
    "def create_print_table(table_name, stream_name, region, stream_initpos):\n",
    "    return \"\"\" CREATE TABLE IF NOT EXISTS {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3),\n",
    "                WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n",
    "\n",
    "              )\n",
    "              WITH (\n",
    "                'connector' = 'print'\n",
    "              ) \"\"\".format(\n",
    "        table_name, stream_name, region, stream_initpos\n",
    "    )\n",
    "\n",
    "def create_output_table(table_name, deliver_stream_name, region):\n",
    "    return f\"\"\" CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3)\n",
    "\n",
    "              )\n",
    "              WITH (\n",
    "                  'connector' = 'firehose',\n",
    "                  'delivery-stream' = '{deliver_stream_name}',\n",
    "                  'aws.region' = '{region}',\n",
    "                  'format' = 'json',\n",
    "                  'json.timestamp-format.standard' = 'ISO-8601'\n",
    "              ) \"\"\"\n",
    "\n",
    "def create_fake_source_table(table_name):\n",
    "    return \"\"\" CREATE TABLE IF NOT EXISTS {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3),\n",
    "                WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n",
    "\n",
    "              )\n",
    "              PARTITIONED BY (ticker)\n",
    "              WITH (\n",
    "                'connector' = 'datagen',\n",
    "                'number-of-rows' = '10'\n",
    "              ) \"\"\".format(table_name)\n",
    "\n",
    "def create_sink_table_s3(table_name, bucket_name):\n",
    "    return \"\"\" CREATE TABLE {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3)\n",
    "              )\n",
    "              PARTITIONED BY (ticker)\n",
    "              WITH (\n",
    "                  'connector'='filesystem',\n",
    "                  'path'='s3a://{1}/',\n",
    "                  'format'='json',\n",
    "                  'sink.partition-commit.policy.kind'='success-file',\n",
    "                  'sink.partition-commit.delay' = '1 min'\n",
    "              ) \"\"\".format(table_name, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating source table input_table from source stream martucci-kinesis-stream-firehose in region us-east-1 using LATEST\n",
      " Creating print table output_table from source stream martucci-kinesis-stream-firehose in region us-east-1.\n",
      " Creating destination table output_table to destination stream martucci-kinesis-delivery-stream in region us-east-1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/viniciusdeoliveiramartucci/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/viniciusdeoliveiramartucci/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py\", line 1217, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-firehose/kinesis-stream-firehose.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-firehose/kinesis-stream-firehose.ipynb#W5sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# 5. Insert from Source to Destination/Print\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-firehose/kinesis-stream-firehose.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m table_result \u001b[39m=\u001b[39m table_env\u001b[39m.\u001b[39mexecute_sql(\u001b[39m\"\u001b[39m\u001b[39mINSERT INTO \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m SELECT * FROM \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-firehose/kinesis-stream-firehose.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                                          \u001b[39m.\u001b[39mformat(output_table_name, input_table_name))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-firehose/kinesis-stream-firehose.ipynb#W5sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m table_result\u001b[39m.\u001b[39;49mwait()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyflink/table/table_result.py:76\u001b[0m, in \u001b[0;36mTableResult.wait\u001b[0;34m(self, timeout_ms)\u001b[0m\n\u001b[1;32m     74\u001b[0m     get_method(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_j_table_result, \u001b[39m\"\u001b[39m\u001b[39mawait\u001b[39m\u001b[39m\"\u001b[39m)(timeout_ms, TimeUnit\u001b[39m.\u001b[39mMILLISECONDS)\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     get_method(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_j_table_result, \u001b[39m\"\u001b[39;49m\u001b[39mawait\u001b[39;49m\u001b[39m\"\u001b[39;49m)()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py:1217\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1214\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError while sending\u001b[39m\u001b[39m\"\u001b[39m, e, proto\u001b[39m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1217\u001b[0m     answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m   1218\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m   1219\u001b[0m     \u001b[39mif\u001b[39;00m answer\u001b[39m.\u001b[39mstartswith(proto\u001b[39m.\u001b[39mRETURN_MESSAGE):\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "# Application Property Keys\n",
    "input_property_group_key = \"consumer.config.0\"\n",
    "producer_property_group_key = \"producer.config.0\"\n",
    "\n",
    "input_stream_key = \"input.stream.name\"\n",
    "input_region_key = \"aws.region\"\n",
    "input_starting_position_key = \"flink.stream.initpos\"\n",
    "\n",
    "output_stream_key = \"output.stream.name\"\n",
    "output_region_key = \"aws.region\"\n",
    "\n",
    "# tables\n",
    "input_table_name = \"input_table\"\n",
    "output_table_name = \"output_table\"\n",
    "\n",
    "# get application properties\n",
    "props = get_application_properties()\n",
    "\n",
    "input_property_map = property_map(props, input_property_group_key)\n",
    "output_property_map = property_map(props, producer_property_group_key)\n",
    "\n",
    "input_stream = input_property_map[input_stream_key]\n",
    "input_region = input_property_map[input_region_key]\n",
    "stream_initpos = input_property_map[input_starting_position_key]\n",
    "\n",
    "output_stream = output_property_map[output_stream_key]\n",
    "output_region = output_property_map[output_region_key]\n",
    "\n",
    "# 0. Creates fake source table from datagen\n",
    "input_table_fake_name = \"fake_source_table\"\n",
    "table_env.execute_sql(\n",
    "    create_fake_source_table(input_table_fake_name)\n",
    ")\n",
    "\n",
    "# 2. Creates a source table from a Kinesis Data Stream\n",
    "print(f\" Creating source table {input_table_name} from source stream {input_stream} in region {input_region} using {stream_initpos}\")\n",
    "table_env.execute_sql(\n",
    "    create_source_table(input_table_name, input_stream, input_region, stream_initpos)\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Creates a print to check Data\n",
    "print_output_table = output_table_name + \"_print\"\n",
    "print(f\" Creating print table {output_table_name} from source stream {input_stream} in region {input_region}.\")\n",
    "table_env.execute_sql(\n",
    "    create_print_table(print_output_table, output_stream, output_region, stream_initpos)\n",
    ")\n",
    "\n",
    "# 4. Creates a sink table writing to a Kinesis Firehose Delivery Strem\n",
    "print(f\" Creating destination table {output_table_name} to destination stream {output_stream} in region {output_region}.\")\n",
    "table_env.execute_sql(\n",
    "    create_output_table(output_table_name,output_stream, output_region)\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Insert from Source to Destination/Print\n",
    "table_result = table_env.execute_sql(\"INSERT INTO {0} SELECT * FROM {1}\"\n",
    "                                         .format(output_table_name, input_table_name))\n",
    "\n",
    "table_result.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
