{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing\n"
     ]
    }
   ],
   "source": [
    "from pyflink.table import EnvironmentSettings, TableEnvironment\n",
    "import os\n",
    "import json\n",
    "from pyflink.table.expressions import *\n",
    "from pyflink.table.window import *\n",
    "\n",
    "# Line only for Local Development\n",
    "os.environ[\"IS_LOCAL\"] = \"True\"\n",
    "\n",
    "print(os.path.abspath(os.getcwd()))\n",
    "#https://docs.aws.amazon.com/pt_br/managed-flink/latest/java/gs-python-createapp.html\n",
    "#https://github.com/aws-samples/amazon-kinesis-data-analytics-examples/blob/master/python/FirehoseSink/streaming-firehose-sink.py\n",
    "#https://github.com/aws-samples/amazon-kinesis-data-analytics-examples/blob/master/python/S3Sink/streaming-file-sink.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Flink locally...\n"
     ]
    }
   ],
   "source": [
    "# 1. Creates a Table Environment\n",
    "env_settings = EnvironmentSettings.in_streaming_mode()\n",
    "table_env = TableEnvironment.create(env_settings)\n",
    "\n",
    "statement_set = table_env.create_statement_set()\n",
    "\n",
    "APPLICATION_PROPERTIES_FILE_PATH = \"/etc/flink/application_properties.json\"  # on Kinesis Data Analytics\n",
    "\n",
    "is_local = (\n",
    "    True if os.environ.get(\"IS_LOCAL\") else False\n",
    ")  # set this env var in your local environment\n",
    "\n",
    "if is_local:\n",
    "    # only for local, overwrite variable to properties and pass in your jars delimited by a semicolon (;)\n",
    "    print(\"Running Flink locally...\")\n",
    "    APPLICATION_PROPERTIES_FILE_PATH = \"application_properties.json\"  # local\n",
    "\n",
    "    CURRENT_DIR = os.path.abspath(os.getcwd())\n",
    "    table_env.get_config().set(\n",
    "        \"pipeline.jars\",\n",
    "        f\"file:///{CURRENT_DIR}/lib/flink-sql-connector-kinesis-4.1.0-1.17.jar\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_application_properties():\n",
    "    if os.path.isfile(APPLICATION_PROPERTIES_FILE_PATH):\n",
    "        with open(APPLICATION_PROPERTIES_FILE_PATH, \"r\") as file:\n",
    "            contents = file.read()\n",
    "            properties = json.loads(contents)\n",
    "            return properties\n",
    "    else:\n",
    "        print('A file at \"{}\" was not found'.format(APPLICATION_PROPERTIES_FILE_PATH))\n",
    "\n",
    "\n",
    "def property_map(props, property_group_id):\n",
    "    for prop in props:\n",
    "        if prop[\"PropertyGroupId\"] == property_group_id:\n",
    "            return prop[\"PropertyMap\"]\n",
    "\n",
    "def create_source_table(table_name, stream_name, region, stream_initpos):\n",
    "    return \"\"\" CREATE TABLE IF NOT EXISTS {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3),\n",
    "                WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n",
    "\n",
    "              )\n",
    "              PARTITIONED BY (ticker)\n",
    "              WITH (\n",
    "                'connector' = 'kinesis',\n",
    "                'stream' = '{1}',\n",
    "                'aws.region' = '{2}',\n",
    "                'scan.stream.initpos' = '{3}',\n",
    "                'format' = 'json',\n",
    "                'json.timestamp-format.standard' = 'ISO-8601'\n",
    "              ) \"\"\".format(\n",
    "        table_name, stream_name, region, stream_initpos\n",
    "    )\n",
    "\n",
    "\n",
    "def create_print_table(table_name, stream_name, region, stream_initpos):\n",
    "    return \"\"\" CREATE TABLE IF NOT EXISTS {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3),\n",
    "                WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n",
    "\n",
    "              )\n",
    "              WITH (\n",
    "                'connector' = 'print'\n",
    "              ) \"\"\".format(\n",
    "        table_name, stream_name, region, stream_initpos\n",
    "    )\n",
    "\n",
    "def create_output_table(table_name, stream_name, region):\n",
    "    return \"\"\" CREATE TABLE IF NOT EXISTS {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                start_timestamp TIMESTAMP(3),\n",
    "                end_timestamp TIMESTAMP(3),\n",
    "                rowtime_timestamp TIMESTAMP(3),\n",
    "                average_price DOUBLE\n",
    "\n",
    "              )\n",
    "              PARTITIONED BY (ticker)\n",
    "              WITH (\n",
    "                'connector' = 'kinesis',\n",
    "                'stream' = '{1}',\n",
    "                'aws.region' = '{2}',\n",
    "                'sink.partitioner-field-delimiter' = ';',\n",
    "                'sink.batch.max-size' = '100',\n",
    "                'format' = 'json',\n",
    "                'json.timestamp-format.standard' = 'ISO-8601'\n",
    "              ) \"\"\".format(\n",
    "        table_name, stream_name, region\n",
    "    )\n",
    "\n",
    "def create_fake_source_table(table_name):\n",
    "    return \"\"\" CREATE TABLE IF NOT EXISTS {0} (\n",
    "                ticker VARCHAR(6),\n",
    "                price DOUBLE,\n",
    "                event_time TIMESTAMP(3),\n",
    "                WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n",
    "\n",
    "              )\n",
    "              PARTITIONED BY (ticker)\n",
    "              WITH (\n",
    "                'connector' = 'datagen',\n",
    "                'number-of-rows' = '10'\n",
    "              ) \"\"\".format(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating source table input_table from source stream martucci-kinesis-stream-firehose in region us-east-1 using LATEST\n",
      " Creating print table output_table from source stream martucci-kinesis-stream-firehose in region us-east-1.\n",
      " Creating destination table output_table to destination stream martucci-kinesis-destination in region us-east-1.\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o313.executeInsert.\n: org.apache.flink.table.api.ValidationException: Column types of query result and sink for 'default_catalog.default_database.output_table' do not match.\nCause: Different number of columns.\n\nQuery schema: [ticker: VARCHAR(6), start_timestamp: TIMESTAMP(3) NOT NULL, end_timestamp: TIMESTAMP(3) NOT NULL, rowtime_timestamp: TIMESTAMP(3) *ROWTIME*, average_price: DOUBLE]\nSink schema:  [ticker: VARCHAR(6), price: DOUBLE, event_time: TIMESTAMP(3)]\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.createSchemaMismatchException(DynamicSinkUtils.java:1010)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.validateSchemaAndApplyImplicitCast(DynamicSinkUtils.java:345)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.validateSchemaAndApplyImplicitCast(DynamicSinkUtils.java:312)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.convertSinkToRel(DynamicSinkUtils.java:272)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.convertSinkToRel(DynamicSinkUtils.java:197)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.$anonfun$translateToRel$1(PlannerBase.scala:275)\n\tat scala.Option.map(Option.scala:146)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.translateToRel(PlannerBase.scala:231)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.$anonfun$translate$1(PlannerBase.scala:181)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:233)\n\tat scala.collection.Iterator.foreach(Iterator.scala:937)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:937)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1425)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:70)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:69)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:233)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:226)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.translate(PlannerBase.scala:181)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.translate(TableEnvironmentImpl.java:1277)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:862)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1097)\n\tat org.apache.flink.table.api.internal.TablePipelineImpl.execute(TablePipelineImpl.java:57)\n\tat org.apache.flink.table.api.Table.executeInsert(Table.java:1074)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)\n\tat org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# specify table program\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m tickets \u001b[39m=\u001b[39m table_env\u001b[39m.\u001b[39mfrom_path(input_table_name)  \u001b[39m# schema (a, b, c, rowtime)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m (tickets\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m.\u001b[39;49mwindow(Tumble\u001b[39m.\u001b[39;49mover(lit(\u001b[39m15\u001b[39;49m)\u001b[39m.\u001b[39;49mseconds)\u001b[39m.\u001b[39;49mon(col(\u001b[39m'\u001b[39;49m\u001b[39mevent_time\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m.\u001b[39;49mgroup_by(col(\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m), col(\u001b[39m'\u001b[39;49m\u001b[39mticker\u001b[39;49m\u001b[39m'\u001b[39;49m)) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39m.\u001b[39;49mselect(col(\u001b[39m'\u001b[39;49m\u001b[39mticker\u001b[39;49m\u001b[39m'\u001b[39;49m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m             col(\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mstart\u001b[39m.\u001b[39;49malias(\u001b[39m'\u001b[39;49m\u001b[39mstart_timestamp\u001b[39;49m\u001b[39m'\u001b[39;49m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m             col(\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mend\u001b[39m.\u001b[39;49malias(\u001b[39m'\u001b[39;49m\u001b[39mend_timestamp\u001b[39;49m\u001b[39m'\u001b[39;49m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m             col(\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mrowtime\u001b[39m.\u001b[39;49malias(\u001b[39m'\u001b[39;49m\u001b[39mrowtime_timestamp\u001b[39;49m\u001b[39m'\u001b[39;49m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m             col(\u001b[39m'\u001b[39;49m\u001b[39mprice\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mavg\u001b[39m.\u001b[39;49malias(\u001b[39m'\u001b[39;49m\u001b[39maverage_price\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m             )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m              \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viniciusdeoliveiramartucci/Documents/GitHub/martucci-glue-streaming/auxiliar-scripts/apache-flink/tutorial-aws-flink/kinesis-stream-to-stream-windowing/gettingstart-table-api-write-to-kinesis-stream.ipynb#W3sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m )\u001b[39m.\u001b[39;49mexecute_insert(output_table_name)\u001b[39m.\u001b[39mwait()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyflink/table/table.py:1045\u001b[0m, in \u001b[0;36mTable.execute_insert\u001b[0;34m(self, table_path_or_descriptor, overwrite)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_t_env\u001b[39m.\u001b[39m_before_execute()\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(table_path_or_descriptor, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1045\u001b[0m     \u001b[39mreturn\u001b[39;00m TableResult(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_j_table\u001b[39m.\u001b[39;49mexecuteInsert(table_path_or_descriptor, overwrite))\n\u001b[1;32m   1046\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1047\u001b[0m     \u001b[39mreturn\u001b[39;00m TableResult(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_j_table\u001b[39m.\u001b[39mexecuteInsert(\n\u001b[1;32m   1048\u001b[0m         table_path_or_descriptor\u001b[39m.\u001b[39m_j_table_descriptor, overwrite))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyflink/util/exceptions.py:146\u001b[0m, in \u001b[0;36mcapture_java_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    147\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    148\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mpyflink\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjava_gateway\u001b[39;00m \u001b[39mimport\u001b[39;00m get_gateway\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o313.executeInsert.\n: org.apache.flink.table.api.ValidationException: Column types of query result and sink for 'default_catalog.default_database.output_table' do not match.\nCause: Different number of columns.\n\nQuery schema: [ticker: VARCHAR(6), start_timestamp: TIMESTAMP(3) NOT NULL, end_timestamp: TIMESTAMP(3) NOT NULL, rowtime_timestamp: TIMESTAMP(3) *ROWTIME*, average_price: DOUBLE]\nSink schema:  [ticker: VARCHAR(6), price: DOUBLE, event_time: TIMESTAMP(3)]\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.createSchemaMismatchException(DynamicSinkUtils.java:1010)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.validateSchemaAndApplyImplicitCast(DynamicSinkUtils.java:345)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.validateSchemaAndApplyImplicitCast(DynamicSinkUtils.java:312)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.convertSinkToRel(DynamicSinkUtils.java:272)\n\tat org.apache.flink.table.planner.connectors.DynamicSinkUtils.convertSinkToRel(DynamicSinkUtils.java:197)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.$anonfun$translateToRel$1(PlannerBase.scala:275)\n\tat scala.Option.map(Option.scala:146)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.translateToRel(PlannerBase.scala:231)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.$anonfun$translate$1(PlannerBase.scala:181)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:233)\n\tat scala.collection.Iterator.foreach(Iterator.scala:937)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:937)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1425)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:70)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:69)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:233)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:226)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.flink.table.planner.delegation.PlannerBase.translate(PlannerBase.scala:181)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.translate(TableEnvironmentImpl.java:1277)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:862)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1097)\n\tat org.apache.flink.table.api.internal.TablePipelineImpl.execute(TablePipelineImpl.java:57)\n\tat org.apache.flink.table.api.Table.executeInsert(Table.java:1074)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)\n\tat org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "# Application Property Keys\n",
    "input_property_group_key = \"consumer.config.0\"\n",
    "producer_property_group_key = \"producer.config.0\"\n",
    "\n",
    "input_stream_key = \"input.stream.name\"\n",
    "input_region_key = \"aws.region\"\n",
    "input_starting_position_key = \"flink.stream.initpos\"\n",
    "\n",
    "output_stream_key = \"output.stream.name\"\n",
    "output_region_key = \"aws.region\"\n",
    "\n",
    "# tables\n",
    "input_table_name = \"input_table\"\n",
    "output_table_name = \"output_table\"\n",
    "\n",
    "# get application properties\n",
    "props = get_application_properties()\n",
    "\n",
    "input_property_map = property_map(props, input_property_group_key)\n",
    "output_property_map = property_map(props, producer_property_group_key)\n",
    "\n",
    "input_stream = input_property_map[input_stream_key]\n",
    "input_region = input_property_map[input_region_key]\n",
    "stream_initpos = input_property_map[input_starting_position_key]\n",
    "\n",
    "output_stream = output_property_map[output_stream_key]\n",
    "output_region = output_property_map[output_region_key]\n",
    "\n",
    "# 0. Creates fake source table from datagen\n",
    "input_table_fake_name = \"fake_source_table\"\n",
    "table_env.execute_sql(\n",
    "    create_fake_source_table(input_table_fake_name)\n",
    ")\n",
    "\n",
    "# 2. Creates a source table from a Kinesis Data Stream\n",
    "print(f\" Creating source table {input_table_name} from source stream {input_stream} in region {input_region} using {stream_initpos}\")\n",
    "table_env.execute_sql(\n",
    "    create_source_table(input_table_name, input_stream, input_region, stream_initpos)\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Creates a print to check Data\n",
    "print_output_table = output_table_name + \"_print\"\n",
    "print(f\" Creating print table {output_table_name} from source stream {input_stream} in region {input_region}.\")\n",
    "table_env.execute_sql(\n",
    "    create_print_table(print_output_table, output_stream, output_region, stream_initpos)\n",
    ")\n",
    "\n",
    "# 4. Creates a sink table writing to a Kinesis Firehose Delivery Strem\n",
    "print(f\" Creating destination table {output_table_name} to destination stream {output_stream} in region {output_region}.\")\n",
    "table_env.execute_sql(\n",
    "    create_output_table(output_table_name,output_stream, output_region)\n",
    ")\n",
    "\n",
    "\n",
    "# specify table program\n",
    "tickets = table_env.from_path(input_table_name)  # schema (a, b, c, rowtime)\n",
    "\n",
    "(tickets\n",
    "    .window(Tumble.over(lit(15).seconds).on(col('event_time')).alias(\"w\"))\n",
    "    .group_by(col('w'), col('ticker')) \n",
    "    .select(col('ticker'), \n",
    "            col('w').start.alias('start_timestamp'), \n",
    "            col('w').end.alias('end_timestamp'), \n",
    "            col('w').rowtime.alias('rowtime_timestamp'), \n",
    "            col('price').avg.alias('average_price')\n",
    "            )\n",
    "             \n",
    ").execute_insert(output_table_name).wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
